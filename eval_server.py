"""
ç¿»è¯‘è¯„ä¼°APIæœåŠ¡å™¨
æä¾›HTTP APIæ¥å£ï¼Œæ”¯æŒç‹¬ç«‹è¿è¡Œ
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import traceback
import sys
import os
import json
import logging
from datetime import datetime
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from translation_evaluator import UnifiedEvaluator, PaperGradeScore

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# Debugæ¨¡å¼é…ç½®ï¼ˆé»˜è®¤å¼€å¯ï¼‰
DEBUG_MODE = True
LOGS_DIR = Path(__file__).parent / "logs"
LOGS_DIR.mkdir(exist_ok=True)

# é…ç½®æ—¥å¿—è®°å½•å™¨
def setup_logger():
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    logger = logging.getLogger('api_debug')
    logger.setLevel(logging.DEBUG)
    
    # é¿å…é‡å¤æ·»åŠ handler
    if logger.handlers:
        return logger
    
    # åˆ›å»ºæ–‡ä»¶handlerï¼ŒæŒ‰æ—¥æœŸå‘½å
    log_file = LOGS_DIR / f"api_{datetime.now().strftime('%Y%m%d')}.log"
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    
    # åˆ›å»ºæ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    return logger

api_logger = setup_logger()

# å…¨å±€è¯„ä¼°å™¨å®ä¾‹å’Œé…ç½®
evaluator = None
evaluator_config = {
    "use_bleu": True,
    "use_comet": True,
    "use_bleurt": False,  # é»˜è®¤å…³é—­ï¼Œéœ€è¦TensorFlowæˆ–å­è¿›ç¨‹æ¨¡å¼
    "use_bertscore": True,
    "use_mqm": True,
    "use_chrf": True,
    "comet_model": None  # Noneè¡¨ç¤ºä½¿ç”¨é»˜è®¤æ¨¡å‹åç§°ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šæœ¬åœ°è·¯å¾„
}

# è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨ï¼ˆå•çº¿ç¨‹å¤„ç†ï¼Œé¿å…å¹¶å‘å‹åŠ›ï¼‰
request_queue = None
USE_QUEUE = os.environ.get("USE_REQUEST_QUEUE", "true").lower() in ("true", "1", "yes")  # é»˜è®¤å¯ç”¨é˜Ÿåˆ—

def init_from_env():
    """
    ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–é…ç½®ï¼ˆç”¨äºgunicornç­‰åœºæ™¯ï¼‰
    """
    import os
    
    print(f"\nğŸ” [DEBUG] å¼€å§‹ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®...")
    print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–USE_BLEURT
    use_bleurt_env = os.environ.get("USE_BLEURT", "")
    print(f"   USE_BLEURTç¯å¢ƒå˜é‡å€¼: {repr(use_bleurt_env)}")
    if use_bleurt_env.lower() in ("true", "1", "yes"):
        evaluator_config["use_bleurt"] = True
        print(f"ğŸ”§ ä»ç¯å¢ƒå˜é‡å¯ç”¨BLEURT: USE_BLEURT={use_bleurt_env}")
    else:
        print(f"   âš ï¸  USE_BLEURTæœªè®¾ç½®æˆ–å€¼ä¸æ­£ç¡®ï¼ŒBLEURTå°†ä¿æŒå…³é—­çŠ¶æ€")
        print(f"   è¯·è®¾ç½®: export USE_BLEURT=true")
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–COMETæ¨¡å‹è·¯å¾„
    comet_model_env = os.environ.get("COMET_MODEL_PATH")
    if comet_model_env:
        evaluator_config["comet_model"] = comet_model_env
        print(f"ğŸ”§ ä»ç¯å¢ƒå˜é‡è¯»å–COMETæ¨¡å‹: {comet_model_env}")
    
    # è®¾ç½®BLEURTå­è¿›ç¨‹æ¨¡å¼ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
    if os.environ.get("BLEURT_USE_SUBPROCESS", "").lower() == "true":
        print(f"ğŸ”§ å¯ç”¨BLEURTå­è¿›ç¨‹æ¨¡å¼")
        if os.environ.get("BLEURT_PYTHON_ENV"):
            print(f"   Pythonç¯å¢ƒ: {os.environ.get('BLEURT_PYTHON_ENV')}")
        if os.environ.get("BLEURT_WORKER_SCRIPT"):
            print(f"   å·¥ä½œè„šæœ¬: {os.environ.get('BLEURT_WORKER_SCRIPT')}")
        if os.environ.get("BLEURT_CHECKPOINT"):
            print(f"   æ£€æŸ¥ç‚¹: {os.environ.get('BLEURT_CHECKPOINT')}")
    
    # è®¾ç½®HuggingFaceç¼“å­˜ç›®å½•
    if os.environ.get("HF_HOME"):
        hf_home = os.environ.get("HF_HOME")
        if "TRANSFORMERS_CACHE" not in os.environ:
            os.environ["TRANSFORMERS_CACHE"] = os.path.join(hf_home, "hub")
        print(f"ğŸ”§ ä½¿ç”¨ç¯å¢ƒå˜é‡HF_HOME: {hf_home}")
    
    print(f"ğŸ” [DEBUG] æœ€ç»ˆé…ç½®: use_bleurt={evaluator_config['use_bleurt']}")
    
    # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œåˆå§‹åŒ–è¯„ä¼°å™¨ï¼Œå› ä¸ºinit_evaluatorå‡½æ•°è¿˜æœªå®šä¹‰
    # è¯„ä¼°å™¨å°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶æˆ–æ¨¡å—å®Œå…¨åŠ è½½ååˆå§‹åŒ–
    if evaluator_config["use_bleurt"]:
        print(f"   âœ… BLEURTå·²é…ç½®ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åˆå§‹åŒ–")
    else:
        print(f"   âš ï¸  BLEURTæœªå¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")

# åœ¨æ¨¡å—åŠ è½½æ—¶ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–ï¼ˆç”¨äºgunicornï¼‰
# æ³¨æ„ï¼šæ­¤æ—¶åªè¯»å–é…ç½®ï¼Œä¸åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆå› ä¸ºinit_evaluatorè¿˜æœªå®šä¹‰ï¼‰
init_from_env()


def init_evaluator(use_bleurt=None, comet_model=None, force_reinit=False):
    """
    åˆå§‹åŒ–è¯„ä¼°å™¨
    
    Args:
        use_bleurt: æ˜¯å¦ä½¿ç”¨BLEURTï¼ˆNoneè¡¨ç¤ºä½¿ç”¨å…¨å±€é…ç½®ï¼‰
        comet_model: COMETæ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨å…¨å±€é…ç½®ï¼‰
        force_reinit: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–ï¼ˆå³ä½¿å·²åˆå§‹åŒ–ï¼‰
    """
    global evaluator, evaluator_config
    
    # å¦‚æœæŒ‡å®šäº†use_bleurtï¼Œæ›´æ–°é…ç½®
    if use_bleurt is not None:
        evaluator_config["use_bleurt"] = use_bleurt
        # å¦‚æœé…ç½®æ”¹å˜ä¸”è¯„ä¼°å™¨å·²åˆå§‹åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
        if evaluator is not None:
            force_reinit = True
    
    # å¦‚æœæŒ‡å®šäº†comet_modelï¼Œæ›´æ–°é…ç½®
    if comet_model is not None:
        evaluator_config["comet_model"] = comet_model
        # å¦‚æœé…ç½®æ”¹å˜ä¸”è¯„ä¼°å™¨å·²åˆå§‹åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
        if evaluator is not None:
            force_reinit = True
    
    if evaluator is None or force_reinit:
        if force_reinit and evaluator is not None:
            print("âš ï¸  æ£€æµ‹åˆ°é…ç½®å˜æ›´ï¼Œé‡æ–°åˆå§‹åŒ–è¯„ä¼°å™¨...")
            evaluator = None
        print("=" * 80)
        print("åˆå§‹åŒ–ç¿»è¯‘è¯„ä¼°å™¨...")
        print("=" * 80)
        
        if evaluator_config["use_bleurt"]:
            print("âš ï¸  å¯ç”¨BLEURTè¯„ä¼°å™¨ï¼ˆéœ€è¦TensorFlowå’Œæ¨¡å‹æ–‡ä»¶ï¼‰")
        
        # è·å–COMETæ¨¡å‹é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œæœ€åä½¿ç”¨é…ç½®ï¼‰
        import os
        comet_model_to_use = comet_model
        if comet_model_to_use is None:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡
            comet_model_to_use = os.environ.get("COMET_MODEL_PATH")
            if comet_model_to_use:
                print(f"ğŸ” [DEBUG] ä»ç¯å¢ƒå˜é‡è¯»å–COMET_MODEL_PATH: {comet_model_to_use}")
        if comet_model_to_use is None:
            # ä½¿ç”¨é…ç½®ä¸­çš„å€¼ï¼ˆå¯èƒ½æ˜¯Noneï¼Œè¡¨ç¤ºä½¿ç”¨é»˜è®¤ï¼‰
            comet_model_to_use = evaluator_config.get("comet_model")
            if comet_model_to_use:
                print(f"ğŸ” [DEBUG] ä»é…ç½®è¯»å–comet_model: {comet_model_to_use}")
        
        if comet_model_to_use:
            print(f"ğŸ“¦ ä½¿ç”¨COMETæ¨¡å‹: {comet_model_to_use}")
            # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
            if os.path.exists(comet_model_to_use):
                print(f"âœ… COMETæ¨¡å‹è·¯å¾„å­˜åœ¨: {comet_model_to_use}")
            else:
                print(f"âš ï¸  COMETæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {comet_model_to_use}")
                print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        else:
            print(f"ğŸ” [DEBUG] æœªæŒ‡å®šCOMETæ¨¡å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹åç§°")
        
        evaluator = UnifiedEvaluator(
            use_bleu=evaluator_config["use_bleu"],
            use_comet=evaluator_config["use_comet"],
            use_bleurt=evaluator_config["use_bleurt"],
            use_bertscore=evaluator_config["use_bertscore"],
            use_mqm=evaluator_config["use_mqm"],
            use_chrf=evaluator_config["use_chrf"],
            comet_model=comet_model_to_use if comet_model_to_use else "Unbabel/wmt22-comet-da"
        )
        
        success = evaluator.initialize()
        
        # æ˜¾ç¤ºå®é™…å¯ç”¨çš„è¯„ä¼°å™¨çŠ¶æ€
        print("\n" + "=" * 80)
        print("è¯„ä¼°å™¨çŠ¶æ€:")
        print("=" * 80)
        
        enabled = []
        failed = []
        
        if evaluator_config["use_bleu"]:
            enabled.append("BLEU")
        
        if evaluator_config["use_comet"]:
            if evaluator.use_comet and evaluator.comet_scorer:
                enabled.append("COMET âœ…")
            else:
                failed.append("COMET âŒ")
        
        if evaluator_config["use_bleurt"]:
            if evaluator.use_bleurt and evaluator.bleurt_scorer:
                enabled.append("BLEURT âœ…")
            else:
                failed.append("BLEURT âŒ (å¯èƒ½ç¼ºå°‘TensorFlowæˆ–æ¨¡å‹æ–‡ä»¶)")
        
        if evaluator_config["use_bertscore"]:
            if evaluator.use_bertscore and evaluator.bertscore_scorer:
                enabled.append("BERTScore âœ…")
            else:
                failed.append("BERTScore âŒ")
        
        if evaluator_config["use_chrf"]:
            if evaluator.use_chrf and evaluator.chrf_scorer:
                enabled.append("ChrF âœ…")
            else:
                failed.append("ChrF âŒ")
        
        if evaluator_config["use_mqm"]:
            enabled.append("MQM")
        
        if enabled:
            print(f"âœ… å·²å¯ç”¨: {', '.join(enabled)}")
        if failed:
            print(f"âš ï¸  åˆå§‹åŒ–å¤±è´¥: {', '.join(failed)}")
        
        if success:
            print("\nâœ… è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆï¼")
        else:
            print("\nâš ï¸  éƒ¨åˆ†è¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½†æœåŠ¡ä»å¯è¿è¡Œ")
        
        print("=" * 80)
        print("APIæœåŠ¡å·²å°±ç»ª")
        print("=" * 80)
        
        # åˆå§‹åŒ–è¯·æ±‚é˜Ÿåˆ—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if USE_QUEUE:
            global request_queue
            from translation_evaluator.request_queue import RequestQueue
            max_queue_size = int(os.environ.get("MAX_QUEUE_SIZE", "50"))
            request_timeout = int(os.environ.get("REQUEST_TIMEOUT", "600"))
            request_queue = RequestQueue(max_queue_size=max_queue_size, request_timeout=request_timeout)
            
            # è®¾ç½®å¤„ç†å›è°ƒ
            def process_eval_request(request_data):
                """å¤„ç†è¯„ä¼°è¯·æ±‚çš„å›è°ƒå‡½æ•°"""
                global evaluator
                if evaluator is None:
                    init_evaluator(
                        use_bleurt=evaluator_config.get("use_bleurt", False),
                        comet_model=evaluator_config.get("comet_model")
                    )
                
                source = request_data.get("source", "")
                translation = request_data.get("translation")
                reference = request_data.get("reference")
                mqm_score = request_data.get("mqm_score")
                
                if not translation or not reference:
                    return {
                        "success": False,
                        "error": "translationå’Œreferenceä¸èƒ½ä¸ºç©º"
                    }
                
                score = evaluator.score(
                    source=source,
                    translation=translation,
                    reference=reference,
                    mqm_score=mqm_score
                )
                
                # è½¬æ¢ä¸ºå­—å…¸
                if isinstance(score, PaperGradeScore):
                    score_dict = {
                        "bleu": score.bleu,
                        "comet": score.comet,
                        "bleurt": score.bleurt,
                        "bertscore_f1": score.bertscore_f1,
                        "chrf": score.chrf,
                        "mqm_adequacy": score.mqm_adequacy,
                        "mqm_fluency": score.mqm_fluency,
                        "mqm_terminology": score.mqm_terminology,
                        "mqm_overall": score.mqm_overall,
                        "final_score": score.final_score,
                        "model_info": score.model_info
                    }
                else:
                    score_dict = score.__dict__ if hasattr(score, '__dict__') else {}
                
                return {
                    "success": True,
                    "score": score_dict
                }
            
            request_queue.set_process_callback(process_eval_request)
            request_queue.start()
            print(f"âœ… è¯·æ±‚é˜Ÿåˆ—å·²å¯ç”¨ (æœ€å¤§é˜Ÿåˆ—é•¿åº¦: {max_queue_size}, è¶…æ—¶: {request_timeout}ç§’)")
        else:
            print(f"âš ï¸  è¯·æ±‚é˜Ÿåˆ—æœªå¯ç”¨ï¼Œå°†ç›´æ¥å¤„ç†è¯·æ±‚ï¼ˆå¯èƒ½å¯¼è‡´å¹¶å‘å‹åŠ›ï¼‰")
    
    return evaluator


@app.route("/", methods=["GET"])
def index():
    """APIé¦–é¡µ"""
    return jsonify({
        "service": "Translation Evaluator API",
        "version": "1.0.0",
        "endpoints": {
            "/": "APIä¿¡æ¯",
            "/health": "å¥åº·æ£€æŸ¥",
            "/eval": "å•ä¸ªæ ·æœ¬è¯„ä¼° (POST)",
            "/eval/batch": "æ‰¹é‡è¯„ä¼° (POST)"
        },
        "usage": {
            "single": {
                "url": "/eval",
                "method": "POST",
                "body": {
                    "source": "æºæ–‡æœ¬ï¼ˆå¯é€‰ï¼‰",
                    "translation": "ç¿»è¯‘æ–‡æœ¬ï¼ˆå¿…éœ€ï¼‰",
                    "reference": "å‚è€ƒç¿»è¯‘ï¼ˆå¿…éœ€ï¼‰",
                    "mqm_score": "MQMè¯„åˆ†ï¼ˆå¯é€‰ï¼‰"
                }
            },
            "batch": {
                "url": "/eval/batch",
                "method": "POST",
                "body": {
                    "sources": ["æºæ–‡æœ¬åˆ—è¡¨"],
                    "translations": ["ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨"],
                    "references": ["å‚è€ƒç¿»è¯‘åˆ—è¡¨"],
                    "mqm_scores": ["MQMè¯„åˆ†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰"]
                }
            }
        }
    })


@app.route("/health", methods=["GET"])
def health():
    """å¥åº·æ£€æŸ¥"""
    evaluator_status = {}
    if evaluator is not None:
        evaluator_status = {
            "use_bleu": evaluator.use_bleu,
            "use_comet": evaluator.use_comet and evaluator.comet_scorer is not None,
            "use_bleurt": evaluator.use_bleurt and evaluator.bleurt_scorer is not None,
            "use_bertscore": evaluator.use_bertscore and evaluator.bertscore_scorer is not None,
            "use_chrf": evaluator.use_chrf and evaluator.chrf_scorer is not None,
            "use_mqm": evaluator.use_mqm
        }
    
    queue_status_info = {}
    if request_queue:
        queue_status_info = request_queue.get_stats()
    
    return jsonify({
        "status": "healthy",
        "evaluator_initialized": evaluator is not None,
        "evaluator_status": evaluator_status,
        "queue_enabled": USE_QUEUE and request_queue is not None,
        "queue_stats": queue_status_info
    })


@app.route("/queue/status/<request_id>", methods=["GET"])
def queue_status(request_id):
    """æŸ¥è¯¢è¯·æ±‚çŠ¶æ€"""
    if not request_queue:
        return jsonify({
            "success": False,
            "error": "è¯·æ±‚é˜Ÿåˆ—æœªå¯ç”¨"
        }), 400
    
    status = request_queue.get_request_status(request_id)
    if status is None:
        return jsonify({
            "success": False,
            "error": "è¯·æ±‚IDä¸å­˜åœ¨"
        }), 404
    
    return jsonify({
        "success": True,
        **status
    })


@app.route("/queue/stats", methods=["GET"])
def queue_stats():
    """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
    if not request_queue:
        return jsonify({
            "success": False,
            "error": "è¯·æ±‚é˜Ÿåˆ—æœªå¯ç”¨"
        }), 400
    
    return jsonify({
        "success": True,
        **request_queue.get_stats()
    })


@app.route("/eval", methods=["POST"])
def eval_text():
    """
    å•ä¸ªæ ·æœ¬è¯„ä¼°ï¼ˆæ”¯æŒé˜Ÿåˆ—æ¨¡å¼ï¼‰
    
    Request Body:
    {
        "source": "æºæ–‡æœ¬ï¼ˆå¯é€‰ï¼‰",
        "translation": "ç¿»è¯‘æ–‡æœ¬ï¼ˆå¿…éœ€ï¼‰",
        "reference": "å‚è€ƒç¿»è¯‘ï¼ˆå¿…éœ€ï¼‰",
        "mqm_score": {
            "adequacy": 0.9,
            "fluency": 0.85,
            "terminology": 0.95,
            "overall": 0.9
        }  // å¯é€‰
    }
    
    Response (é˜Ÿåˆ—æ¨¡å¼):
    {
        "success": true,
        "request_id": "uuid",
        "status": "queued",
        "queue_position": 1,
        "message": "è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ—ï¼Œå½“å‰æ’é˜Ÿä½ç½®: 1"
    }
    
    Response (ç›´æ¥æ¨¡å¼):
    {
        "success": true,
        "score": {
            "bleu": 0.85,
            "comet": 0.92,
            ...
        }
    }
    """
    # å¦‚æœå¯ç”¨é˜Ÿåˆ—æ¨¡å¼ï¼Œä½¿ç”¨é˜Ÿåˆ—å¤„ç†
    if USE_QUEUE and request_queue:
        data = request.json
        if not data:
            return jsonify({
                "success": False,
                "error": "è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º"
            }), 400
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if "translation" not in data or "reference" not in data:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…éœ€å­—æ®µ: translation æˆ– reference"
            }), 400
        
        # æäº¤åˆ°é˜Ÿåˆ—
        result = request_queue.submit_request(data)
        
        if result.get("success"):
            return jsonify(result), 202  # 202 Accepted - è¯·æ±‚å·²æ¥å—ï¼Œæ­£åœ¨å¤„ç†
        else:
            return jsonify(result), 503  # 503 Service Unavailable - é˜Ÿåˆ—å·²æ»¡
    
    # ç›´æ¥å¤„ç†æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    request_id = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
    
    try:
        if DEBUG_MODE:
            api_logger.info("=" * 100)
            api_logger.info(f"ğŸ“¥ [è¯·æ±‚ID: {request_id}] æ”¶åˆ°å•ä¸ªæ ·æœ¬è¯„ä¼°è¯·æ±‚")
            api_logger.info("=" * 100)
        # ç¡®ä¿è¯„ä¼°å™¨å·²åˆå§‹åŒ–
        if evaluator is None:
            # ä½¿ç”¨é…ç½®ä¸­çš„å€¼åˆå§‹åŒ–ï¼ˆå¯èƒ½å·²ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            init_evaluator(
                use_bleurt=evaluator_config.get("use_bleurt", False),
                comet_model=evaluator_config.get("comet_model")
            )
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.json
        if not data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] è¯·æ±‚ä½“ä¸ºç©º")
            return jsonify({
                "success": False,
                "error": "è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º"
            }), 400
        
        # è®°å½•è¯·æ±‚æ•°æ®
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“‹ è¯·æ±‚æ•°æ®:")
            api_logger.info(f"  - translationé•¿åº¦: {len(data.get('translation', ''))}")
            api_logger.info(f"  - referenceé•¿åº¦: {len(data.get('reference', ''))}")
            api_logger.info(f"  - sourceé•¿åº¦: {len(data.get('source', ''))}")
            api_logger.info(f"  - æ˜¯å¦æœ‰mqm_score: {'mqm_score' in data and data['mqm_score'] is not None}")
            if DEBUG_MODE:
                # è®°å½•å®Œæ•´æ•°æ®ï¼ˆæˆªæ–­é•¿æ–‡æœ¬ï¼‰
                log_data = data.copy()
                for key in ['translation', 'reference', 'source']:
                    if key in log_data and len(log_data[key]) > 200:
                        log_data[key] = log_data[key][:200] + f"... (æ€»é•¿åº¦: {len(data[key])})"
                api_logger.debug(f"[è¯·æ±‚ID: {request_id}] å®Œæ•´è¯·æ±‚æ•°æ®: {json.dumps(log_data, ensure_ascii=False, indent=2)}")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if "translation" not in data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] ç¼ºå°‘å¿…éœ€å­—æ®µ: translation")
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…éœ€å­—æ®µ: translation"
            }), 400
        
        if "reference" not in data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] ç¼ºå°‘å¿…éœ€å­—æ®µ: reference")
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…éœ€å­—æ®µ: reference"
            }), 400
        
        # æ‰§è¡Œè¯„ä¼°
        reference = data["reference"]
        translation = data["translation"]
        source = data.get("source", "")
        mqm_score = data.get("mqm_score")
        
        # è®°å½•è¯„ä¼°å™¨çŠ¶æ€
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ”§ è¯„ä¼°å™¨çŠ¶æ€:")
            api_logger.info(f"  - use_bleu: {evaluator.use_bleu}")
            api_logger.info(f"  - use_comet: {evaluator.use_comet}")
            api_logger.info(f"  - use_bleurt: {evaluator.use_bleurt}")
            api_logger.info(f"  - use_bertscore: {evaluator.use_bertscore}")
            api_logger.info(f"  - use_chrf: {evaluator.use_chrf}")
            api_logger.info(f"  - use_mqm: {evaluator.use_mqm}")
            api_logger.info(f"  - COMETè¯„ä¼°å™¨å­˜åœ¨: {evaluator.comet_scorer is not None}")
            api_logger.info(f"  - BLEURTè¯„ä¼°å™¨å­˜åœ¨: {evaluator.bleurt_scorer is not None}")
            api_logger.info(f"  - BERTScoreè¯„ä¼°å™¨å­˜åœ¨: {evaluator.bertscore_scorer is not None}")
            api_logger.info(f"  - ChrFè¯„ä¼°å™¨å­˜åœ¨: {evaluator.chrf_scorer is not None}")
        
        # éªŒè¯referenceä¸ä¸ºç©º
        if not reference or not reference.strip():
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] referenceä¸ºç©º")
            return jsonify({
                "success": False,
                "error": "referenceä¸èƒ½ä¸ºç©ºï¼ˆBLEURTç­‰è¯„ä¼°å™¨éœ€è¦referenceï¼‰"
            }), 400
        
        # å¼€å§‹è¯„ä¼°
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸš€ å¼€å§‹è¯„ä¼°...")
            start_time = datetime.now()
        
        score = evaluator.score(
            source=source,
            translation=translation,
            reference=reference,
            mqm_score=mqm_score
        )
        
        # è®°å½•è¯„ä¼°ç»“æœ
        if DEBUG_MODE:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] âœ… è¯„ä¼°å®Œæˆ (è€—æ—¶: {duration:.3f}ç§’)")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“Š è¯„ä¼°ç»“æœ:")
            api_logger.info(f"  - BLEU: {score.bleu:.6f}")
            api_logger.info(f"  - COMET: {score.comet:.6f}")
            api_logger.info(f"  - BLEURT: {score.bleurt:.6f}")
            api_logger.info(f"  - BERTScore F1: {score.bertscore_f1:.6f}")
            api_logger.info(f"  - ChrF: {score.chrf:.6f}")
            api_logger.info(f"  - MQM Adequacy: {score.mqm_adequacy:.6f}")
            api_logger.info(f"  - MQM Fluency: {score.mqm_fluency:.6f}")
            api_logger.info(f"  - MQM Terminology: {score.mqm_terminology:.6f}")
            api_logger.info(f"  - MQM Overall: {score.mqm_overall:.6f}")
            api_logger.info(f"  - ç»¼åˆè¯„åˆ†: {score.final_score:.6f}")
            if hasattr(score, 'model_info') and score.model_info:
                api_logger.info(f"  - æ¨¡å‹ä¿¡æ¯: {score.model_info}")
        
        # è½¬æ¢ä¸ºå­—å…¸ï¼ˆå¤„ç†dataclassï¼‰
        if isinstance(score, PaperGradeScore):
            score_dict = {
                "bleu": score.bleu,
                "comet": score.comet,
                "bleurt": score.bleurt,  # ç¡®ä¿BLEURTæ€»æ˜¯åŒ…å«åœ¨è¿”å›ç»“æœä¸­
                "bertscore_f1": score.bertscore_f1,
                "chrf": score.chrf,
                "mqm_adequacy": score.mqm_adequacy,
                "mqm_fluency": score.mqm_fluency,
                "mqm_terminology": score.mqm_terminology,
                "mqm_overall": score.mqm_overall,
                "final_score": score.final_score,
                "model_info": score.model_info
            }
            # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœBLEURTä¸º0ä½†è¯„ä¼°å™¨å·²å¯ç”¨ï¼Œè®°å½•æ—¥å¿—
            if evaluator.use_bleurt and score.bleurt == 0.0:
                if DEBUG_MODE:
                    api_logger.warning(f"[è¯·æ±‚ID: {request_id}] âš ï¸  BLEURTå·²å¯ç”¨ä½†åˆ†æ•°ä¸º0")
        else:
            score_dict = score.__dict__ if hasattr(score, '__dict__') else {}
            # ç¡®ä¿BLEURTå­—æ®µå­˜åœ¨
            if "bleurt" not in score_dict:
                score_dict["bleurt"] = 0.0
        
        # è®°å½•è¿”å›ç»“æœ
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“¤ è¿”å›ç»“æœ:")
            api_logger.debug(f"[è¯·æ±‚ID: {request_id}] å®Œæ•´è¿”å›æ•°æ®: {json.dumps(score_dict, ensure_ascii=False, indent=2)}")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] " + "=" * 100)
        
        return jsonify({
            "success": True,
            "score": score_dict
        })
        
    except Exception as e:
        error_msg = str(e)
        traceback_str = traceback.format_exc()
        
        if DEBUG_MODE:
            api_logger.error(f"[è¯·æ±‚ID: {request_id}] âŒ è¯„ä¼°é”™è¯¯: {error_msg}")
            api_logger.error(f"[è¯·æ±‚ID: {request_id}] é”™è¯¯å †æ ˆ:\n{traceback_str}")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] " + "=" * 100)
        
        return jsonify({
            "success": False,
            "error": error_msg,
            "traceback": traceback_str if app.debug else None
        }), 500


@app.route("/eval/batch", methods=["POST"])
def eval_batch():
    """
    æ‰¹é‡è¯„ä¼°
    
    Request Body:
    {
        "sources": ["æºæ–‡æœ¬1", "æºæ–‡æœ¬2", ...],
        "translations": ["ç¿»è¯‘1", "ç¿»è¯‘2", ...],
        "references": ["å‚è€ƒ1", "å‚è€ƒ2", ...],
        "mqm_scores": [
            {"overall": 0.9},
            {"overall": 0.85}
        ]  // å¯é€‰
    }
    
    Response:
    {
        "success": true,
        "scores": [
            {
                "bleu": 0.85,
                "comet": 0.92,
                ...
            },
            ...
        ]
    }
    """
    request_id = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
    
    try:
        if DEBUG_MODE:
            api_logger.info("=" * 100)
            api_logger.info(f"ğŸ“¥ [è¯·æ±‚ID: {request_id}] æ”¶åˆ°æ‰¹é‡è¯„ä¼°è¯·æ±‚")
            api_logger.info("=" * 100)
        # ç¡®ä¿è¯„ä¼°å™¨å·²åˆå§‹åŒ–
        if evaluator is None:
            # ä½¿ç”¨é…ç½®ä¸­çš„å€¼åˆå§‹åŒ–ï¼ˆå¯èƒ½å·²ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            init_evaluator(
                use_bleurt=evaluator_config.get("use_bleurt", False),
                comet_model=evaluator_config.get("comet_model")
            )
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.json
        if not data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] è¯·æ±‚ä½“ä¸ºç©º")
            return jsonify({
                "success": False,
                "error": "è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º"
            }), 400
        
        # è®°å½•è¯·æ±‚æ•°æ®
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“‹ è¯·æ±‚æ•°æ®:")
            api_logger.info(f"  - translationsæ•°é‡: {len(data.get('translations', []))}")
            api_logger.info(f"  - referencesæ•°é‡: {len(data.get('references', []))}")
            api_logger.info(f"  - sourcesæ•°é‡: {len(data.get('sources', []))}")
            api_logger.info(f"  - mqm_scoresæ•°é‡: {len(data.get('mqm_scores', []))}")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if "translations" not in data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] ç¼ºå°‘å¿…éœ€å­—æ®µ: translations")
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…éœ€å­—æ®µ: translations"
            }), 400
        
        if "references" not in data:
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] ç¼ºå°‘å¿…éœ€å­—æ®µ: references")
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…éœ€å­—æ®µ: references"
            }), 400
        
        translations = data["translations"]
        references = data["references"]
        sources = data.get("sources", [""] * len(translations))
        mqm_scores = data.get("mqm_scores", [None] * len(translations))
        
        # éªŒè¯é•¿åº¦
        if len(translations) != len(references):
            if DEBUG_MODE:
                api_logger.error(f"[è¯·æ±‚ID: {request_id}] é•¿åº¦ä¸åŒ¹é…: translations={len(translations)}, references={len(references)}")
            return jsonify({
                "success": False,
                "error": f"translationså’Œreferencesé•¿åº¦ä¸åŒ¹é…: {len(translations)} vs {len(references)}"
            }), 400
        
        # è®°å½•è¯„ä¼°å™¨çŠ¶æ€
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ”§ è¯„ä¼°å™¨çŠ¶æ€:")
            api_logger.info(f"  - use_bleu: {evaluator.use_bleu}")
            api_logger.info(f"  - use_comet: {evaluator.use_comet}")
            api_logger.info(f"  - use_bleurt: {evaluator.use_bleurt}")
            api_logger.info(f"  - use_bertscore: {evaluator.use_bertscore}")
            api_logger.info(f"  - use_chrf: {evaluator.use_chrf}")
            api_logger.info(f"  - use_mqm: {evaluator.use_mqm}")
        
        # å¼€å§‹æ‰¹é‡è¯„ä¼°
        if DEBUG_MODE:
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸš€ å¼€å§‹æ‰¹é‡è¯„ä¼°...")
            start_time = datetime.now()
        
        results = evaluator.batch_score(
            sources=sources,
            translations=translations,
            references=references,
            mqm_scores=mqm_scores if mqm_scores else None
        )
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        scores_list = []
        for i, score in enumerate(results):
            if isinstance(score, PaperGradeScore):
                score_dict = {
                    "bleu": score.bleu,
                    "comet": score.comet,
                    "bleurt": score.bleurt,
                    "bertscore_f1": score.bertscore_f1,
                    "chrf": score.chrf,
                    "mqm_adequacy": score.mqm_adequacy,
                    "mqm_fluency": score.mqm_fluency,
                    "mqm_terminology": score.mqm_terminology,
                    "mqm_overall": score.mqm_overall,
                    "final_score": score.final_score
                }
            else:
                score_dict = score.__dict__ if hasattr(score, '__dict__') else {}
            scores_list.append(score_dict)
            
            # è®°å½•æ¯ä¸ªæ ·æœ¬çš„è¯„ä¼°ç»“æœ
            if DEBUG_MODE:
                api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“Š æ ·æœ¬ {i+1}/{len(results)} è¯„ä¼°ç»“æœ:")
                api_logger.info(f"  - BLEU: {score_dict.get('bleu', 0):.6f}")
                api_logger.info(f"  - COMET: {score_dict.get('comet', 0):.6f}")
                api_logger.info(f"  - BLEURT: {score_dict.get('bleurt', 0):.6f}")
                api_logger.info(f"  - BERTScore F1: {score_dict.get('bertscore_f1', 0):.6f}")
                api_logger.info(f"  - ChrF: {score_dict.get('chrf', 0):.6f}")
                api_logger.info(f"  - ç»¼åˆè¯„åˆ†: {score_dict.get('final_score', 0):.6f}")
        
        if DEBUG_MODE:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] âœ… æ‰¹é‡è¯„ä¼°å®Œæˆ (æ€»è€—æ—¶: {duration:.3f}ç§’, å¹³å‡: {duration/len(results):.3f}ç§’/æ ·æœ¬)")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] ğŸ“¤ è¿”å› {len(scores_list)} ä¸ªè¯„ä¼°ç»“æœ")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] " + "=" * 100)
        
        return jsonify({
            "success": True,
            "count": len(scores_list),
            "scores": scores_list
        })
        
    except Exception as e:
        error_msg = str(e)
        traceback_str = traceback.format_exc()
        
        if DEBUG_MODE:
            api_logger.error(f"[è¯·æ±‚ID: {request_id}] âŒ æ‰¹é‡è¯„ä¼°é”™è¯¯: {error_msg}")
            api_logger.error(f"[è¯·æ±‚ID: {request_id}] é”™è¯¯å †æ ˆ:\n{traceback_str}")
            api_logger.info(f"[è¯·æ±‚ID: {request_id}] " + "=" * 100)
        
        return jsonify({
            "success": False,
            "error": error_msg,
            "traceback": traceback_str if app.debug else None
        }), 500


if __name__ == "__main__":
    import argparse
    import os
    
    parser = argparse.ArgumentParser(description="ç¿»è¯‘è¯„ä¼°APIæœåŠ¡å™¨")
    parser.add_argument("--host", default="0.0.0.0", help="ç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0)")
    parser.add_argument("--port", type=int, default=5001, help="ç›‘å¬ç«¯å£ (é»˜è®¤: 5001)")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨Flaskè°ƒè¯•æ¨¡å¼")
    parser.add_argument("--use-bleurt", action="store_true", help="å¯ç”¨BLEURTè¯„ä¼°å™¨")
    parser.add_argument("--bleurt-subprocess", action="store_true", 
                       help="ä½¿ç”¨å­è¿›ç¨‹æ¨¡å¼è¿è¡ŒBLEURTï¼ˆé¿å…ç¯å¢ƒå†²çªï¼‰")
    parser.add_argument("--bleurt-python-env", type=str, default=None,
                       help="BLEURTçš„Pythonç¯å¢ƒè·¯å¾„ (ä¾‹å¦‚: /path/to/bleurt_env/bin/python)")
    parser.add_argument("--bleurt-worker-script", type=str, default=None,
                       help="BLEURTå·¥ä½œè„šæœ¬è·¯å¾„ (é»˜è®¤: ./bleurt_worker.py)")
    parser.add_argument("--bleurt-checkpoint", type=str, default=None,
                       help="BLEURTæ£€æŸ¥ç‚¹è·¯å¾„ (é»˜è®¤: BLEURT-20)")
    parser.add_argument("--comet-model", type=str, default=None, 
                       help="COMETæ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„ (ä¾‹å¦‚: /path/to/comet/model æˆ– Unbabel/wmt22-comet-da)")
    parser.add_argument("--hf-home", type=str, default=None,
                       help="HuggingFaceç¼“å­˜ç›®å½• (ä¾‹å¦‚: /root/.cache/huggingface)")
    parser.add_argument("--no-api-debug", action="store_true", help="ç¦ç”¨APIè¯·æ±‚è°ƒè¯•æ—¥å¿—ï¼ˆé»˜è®¤å¼€å¯ï¼‰")
    
    args = parser.parse_args()
    
    # è®¾ç½®BLEURTç¯å¢ƒå˜é‡ï¼ˆå­è¿›ç¨‹æ¨¡å¼ï¼‰
    if args.bleurt_subprocess:
        os.environ["BLEURT_USE_SUBPROCESS"] = "true"
        if args.bleurt_python_env:
            os.environ["BLEURT_PYTHON_ENV"] = args.bleurt_python_env
        if args.bleurt_worker_script:
            os.environ["BLEURT_WORKER_SCRIPT"] = args.bleurt_worker_script
        if args.bleurt_checkpoint:
            os.environ["BLEURT_CHECKPOINT"] = args.bleurt_checkpoint
        print(f"ğŸ”§ å¯ç”¨BLEURTå­è¿›ç¨‹æ¨¡å¼")
        if args.bleurt_python_env:
            print(f"   Pythonç¯å¢ƒ: {args.bleurt_python_env}")
        if args.bleurt_worker_script:
            print(f"   å·¥ä½œè„šæœ¬: {args.bleurt_worker_script}")
        if args.bleurt_checkpoint:
            print(f"   æ£€æŸ¥ç‚¹: {args.bleurt_checkpoint}")
    
    # è®¾ç½®HuggingFaceç¯å¢ƒå˜é‡ï¼ˆç”¨äºç¦»çº¿æ¨¡å¼ï¼‰
    # æ³¨æ„ï¼šTRANSFORMERS_CACHEå·²å¼ƒç”¨ï¼Œä½¿ç”¨HF_HOME
    if args.hf_home:
        os.environ["HF_HOME"] = args.hf_home
        # TRANSFORMERS_CACHEå·²å¼ƒç”¨ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ä»è®¾ç½®
        if "TRANSFORMERS_CACHE" not in os.environ:
            os.environ["TRANSFORMERS_CACHE"] = os.path.join(args.hf_home, "hub")
        print(f"ğŸ”§ è®¾ç½®HuggingFaceç¼“å­˜ç›®å½•: {args.hf_home}")
    elif os.environ.get("HF_HOME"):
        hf_home = os.environ.get("HF_HOME")
        if "TRANSFORMERS_CACHE" not in os.environ:
            os.environ["TRANSFORMERS_CACHE"] = os.path.join(hf_home, "hub")
        print(f"ğŸ”§ ä½¿ç”¨ç¯å¢ƒå˜é‡HF_HOME: {hf_home}")
    else:
        # ä½¿ç”¨é»˜è®¤è·¯å¾„
        default_hf_home = os.path.expanduser("~/.cache/huggingface")
        if os.path.exists(default_hf_home):
            os.environ["HF_HOME"] = default_hf_home
            if "TRANSFORMERS_CACHE" not in os.environ:
                os.environ["TRANSFORMERS_CACHE"] = os.path.join(default_hf_home, "hub")
            print(f"ğŸ”§ ä½¿ç”¨é»˜è®¤HuggingFaceç¼“å­˜ç›®å½•: {default_hf_home}")
        else:
            # å³ä½¿ç›®å½•ä¸å­˜åœ¨ä¹Ÿè®¾ç½®ï¼Œè®©åº“åˆ›å»º
            os.environ["HF_HOME"] = default_hf_home
            print(f"ğŸ”§ è®¾ç½®HuggingFaceç¼“å­˜ç›®å½•ï¼ˆå°†åˆ›å»ºï¼‰: {default_hf_home}")
    
    # è®¾ç½®DEBUG_MODE
    DEBUG_MODE = not args.no_api_debug
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆä¼ é€’use_bleurtå’Œcomet_modelå‚æ•°ï¼‰
    # ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®é»˜è®¤å€¼
    import os
    use_bleurt = args.use_bleurt if args.use_bleurt else (
        os.environ.get("USE_BLEURT", "").lower() in ("true", "1", "yes") or 
        evaluator_config.get("use_bleurt", False)
    )
    comet_model = args.comet_model if args.comet_model else (
        os.environ.get("COMET_MODEL_PATH") or None
    )
    
    print(f"\nğŸ” [DEBUG] é…ç½®ä¿¡æ¯:")
    print(f"   BLEURT: {use_bleurt}")
    if comet_model:
        print(f"   COMETæ¨¡å‹: {comet_model}")
    else:
        import os
        env_comet = os.environ.get("COMET_MODEL_PATH")
        if env_comet:
            print(f"   COMETæ¨¡å‹ (ç¯å¢ƒå˜é‡): {env_comet}")
        else:
            print(f"   COMETæ¨¡å‹: ä½¿ç”¨é»˜è®¤")
    
    init_evaluator(use_bleurt=use_bleurt, comet_model=comet_model)
    
    print(f"\nğŸš€ å¯åŠ¨APIæœåŠ¡å™¨...")
    print(f"   åœ°å€: http://{args.host}:{args.port}")
    print(f"   Flaskè°ƒè¯•æ¨¡å¼: {args.debug}")
    print(f"   APIè¯·æ±‚è°ƒè¯•æ—¥å¿—: {'å¼€å¯' if DEBUG_MODE else 'å…³é—­'}")
    print(f"   æ—¥å¿—ç›®å½•: {LOGS_DIR}")
    if DEBUG_MODE:
        log_file = LOGS_DIR / f"api_{datetime.now().strftime('%Y%m%d')}.log"
        print(f"   æ—¥å¿—æ–‡ä»¶: {log_file}")
    print(f"\nğŸ“– APIæ–‡æ¡£: http://{args.host}:{args.port}/")
    print(f"ğŸ’š å¥åº·æ£€æŸ¥: http://{args.host}:{args.port}/health")
    print(f"ğŸ“Š è¯„ä¼°æ¥å£: http://{args.host}:{args.port}/eval")
    print(f"ğŸ“¦ æ‰¹é‡è¯„ä¼°: http://{args.host}:{args.port}/eval/batch")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨\n")
    
    app.run(host=args.host, port=args.port, debug=args.debug)

