# 请求队列使用指南

## 📋 概述

为了应对多用户同时调用翻译评估服务导致的服务器压力问题，我们实现了**请求队列机制**，确保单线程处理请求，避免并发压力。

## 🎯 核心特性

1. **单线程处理**：确保同一时间只有一个请求在处理，避免资源竞争
2. **排队机制**：用户A在处理时，用户B会收到"服务器排队中，请稍后重试"的反馈
3. **状态跟踪**：每个请求都有唯一ID，可以查询处理状态
4. **超时保护**：防止请求无限等待
5. **队列限制**：防止队列过长导致内存溢出

## 🚀 快速开始

### 1. 启用队列模式（默认已启用）

队列模式默认启用，可以通过环境变量控制：

```bash
# 启用队列（默认）
export USE_REQUEST_QUEUE=true

# 禁用队列（直接处理，可能导致并发压力）
export USE_REQUEST_QUEUE=false
```

### 2. 配置队列参数

```bash
# 最大队列长度（默认：50）
export MAX_QUEUE_SIZE=50

# 请求超时时间（秒，默认：600秒=10分钟）
export REQUEST_TIMEOUT=600
```

### 3. 启动服务

```bash
# 使用gunicorn（推荐）
gunicorn -w 1 -b 0.0.0.0:5001 --timeout 600 eval_server:app

# 或直接运行
python eval_server.py
```

**注意**：使用队列模式时，建议gunicorn worker数量设为1（`-w 1`），因为队列本身已经实现了单线程处理。

## 📡 API使用

### 1. 提交评估请求

**请求**：
```bash
POST http://localhost:5001/eval
Content-Type: application/json

{
    "translation": "Hello world",
    "reference": "你好世界",
    "source": "Hello world"  // 可选
}
```

**响应（队列模式）**：
```json
{
    "success": true,
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "status": "queued",
    "queue_position": 1,
    "message": "请求已加入队列，当前排队位置: 1"
}
```

**HTTP状态码**：
- `202 Accepted`：请求已接受，正在排队或处理
- `503 Service Unavailable`：队列已满，请稍后重试

### 2. 查询请求状态

**请求**：
```bash
GET http://localhost:5001/queue/status/{request_id}
```

**响应**：
```json
{
    "success": true,
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "status": "processing",  // queued, processing, completed, failed, timeout
    "queue_position": 0,
    "created_at": "2026-02-06T10:30:00",
    "started_at": "2026-02-06T10:30:05",
    "completed_at": null,
    "wait_time": 5.2,
    "result": null,
    "error": null
}
```

**状态说明**：
- `queued`：排队中
- `processing`：处理中
- `completed`：已完成（结果在`result`字段）
- `failed`：处理失败（错误在`error`字段）
- `timeout`：超时

### 3. 获取队列统计

**请求**：
```bash
GET http://localhost:5001/queue/stats
```

**响应**：
```json
{
    "success": true,
    "queue_size": 3,
    "current_processing": "550e8400-e29b-41d4-a716-446655440000",
    "total_requests": 100,
    "completed_requests": 95,
    "failed_requests": 2,
    "timeout_requests": 0,
    "max_queue_size": 50,
    "request_timeout": 600
}
```

### 4. 健康检查（包含队列信息）

**请求**：
```bash
GET http://localhost:5001/health
```

**响应**：
```json
{
    "status": "healthy",
    "evaluator_initialized": true,
    "evaluator_status": {...},
    "queue_enabled": true,
    "queue_stats": {
        "queue_size": 3,
        "current_processing": "...",
        "total_requests": 100,
        ...
    }
}
```

## 💡 客户端使用示例

### Python客户端

```python
import requests
import time

def evaluate_with_queue(translation, reference, source=None):
    """使用队列模式评估"""
    base_url = "http://localhost:5001"
    
    # 1. 提交请求
    response = requests.post(
        f"{base_url}/eval",
        json={
            "translation": translation,
            "reference": reference,
            "source": source
        }
    )
    
    if response.status_code == 503:
        # 队列已满
        return {"error": "服务器队列已满，请稍后重试"}
    
    if response.status_code != 202:
        # 其他错误
        return {"error": response.json()}
    
    data = response.json()
    request_id = data["request_id"]
    
    # 2. 轮询查询状态
    max_wait = 600  # 最大等待10分钟
    poll_interval = 2  # 每2秒查询一次
    start_time = time.time()
    
    while time.time() - start_time < max_wait:
        status_response = requests.get(f"{base_url}/queue/status/{request_id}")
        if status_response.status_code == 404:
            return {"error": "请求ID不存在"}
        
        status_data = status_response.json()
        status = status_data["status"]
        
        if status == "completed":
            return status_data["result"]
        elif status == "failed":
            return {"error": status_data["error"]}
        elif status == "timeout":
            return {"error": "请求超时"}
        
        # 排队中或处理中，继续等待
        print(f"状态: {status}, 排队位置: {status_data.get('queue_position', 0)}")
        time.sleep(poll_interval)
    
    return {"error": "等待超时"}

# 使用示例
result = evaluate_with_queue(
    translation="Hello world",
    reference="你好世界"
)
print(result)
```

### JavaScript客户端

```javascript
async function evaluateWithQueue(translation, reference, source = null) {
    const baseUrl = 'http://localhost:5001';
    
    // 1. 提交请求
    const submitResponse = await fetch(`${baseUrl}/eval`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ translation, reference, source })
    });
    
    if (submitResponse.status === 503) {
        return { error: '服务器队列已满，请稍后重试' };
    }
    
    if (submitResponse.status !== 202) {
        const error = await submitResponse.json();
        return { error };
    }
    
    const { request_id } = await submitResponse.json();
    
    // 2. 轮询查询状态
    const maxWait = 600000; // 10分钟
    const pollInterval = 2000; // 2秒
    const startTime = Date.now();
    
    while (Date.now() - startTime < maxWait) {
        const statusResponse = await fetch(`${baseUrl}/queue/status/${request_id}`);
        if (statusResponse.status === 404) {
            return { error: '请求ID不存在' };
        }
        
        const statusData = await statusResponse.json();
        const { status, result, error } = statusData;
        
        if (status === 'completed') {
            return result;
        } else if (status === 'failed') {
            return { error };
        } else if (status === 'timeout') {
            return { error: '请求超时' };
        }
        
        // 排队中或处理中，继续等待
        console.log(`状态: ${status}, 排队位置: ${statusData.queue_position || 0}`);
        await new Promise(resolve => setTimeout(resolve, pollInterval));
    }
    
    return { error: '等待超时' };
}

// 使用示例
evaluateWithQueue('Hello world', '你好世界')
    .then(result => console.log(result))
    .catch(error => console.error(error));
```

## ⚠️ 潜在风险与应对措施

### 1. 内存泄漏风险

**问题**：请求记录会一直保存在内存中，可能导致内存泄漏。

**应对**：
- 队列会自动清理1小时前的已完成请求
- 可以通过调整`MAX_QUEUE_SIZE`限制队列长度
- 定期重启服务（建议使用systemd自动重启）

### 2. 超时风险

**问题**：如果请求处理时间过长，可能超时。

**应对**：
- 默认超时时间为600秒（10分钟）
- 可以通过`REQUEST_TIMEOUT`环境变量调整
- 客户端应该设置合理的轮询超时时间

### 3. 队列满风险

**问题**：如果队列已满，新请求会被拒绝。

**应对**：
- 客户端应该实现重试机制（指数退避）
- 监控队列统计，及时扩容或增加worker
- 考虑使用负载均衡分发到多个服务实例

### 4. 服务崩溃风险

**问题**：如果服务崩溃，队列中的请求会丢失。

**应对**：
- 使用systemd或supervisor自动重启服务
- 考虑实现持久化队列（Redis/RabbitMQ）
- 客户端应该实现重试机制

### 5. 模型加载阻塞

**问题**：COMET等模型加载可能阻塞队列处理。

**应对**：
- 已实现文件锁机制，避免多进程同时加载
- 使用`--preload`选项预加载模型
- 建议gunicorn worker数量设为1

### 6. 资源竞争

**问题**：多个评估器同时运行可能导致资源竞争。

**应对**：
- 队列机制确保单线程处理
- BLEURT使用子进程模式隔离环境
- COMET使用文件锁避免并发加载

## 🔧 配置建议

### 生产环境配置

```bash
# 环境变量
export USE_REQUEST_QUEUE=true
export MAX_QUEUE_SIZE=50
export REQUEST_TIMEOUT=600

# gunicorn启动（单worker，预加载模型）
gunicorn -w 1 -b 0.0.0.0:5001 --timeout 600 --preload eval_server:app
```

### 开发环境配置

```bash
# 禁用队列，直接处理（方便调试）
export USE_REQUEST_QUEUE=false

# 直接运行
python eval_server.py
```

## 📊 监控建议

1. **队列统计**：定期查询`/queue/stats`，监控队列长度和处理速度
2. **错误日志**：监控失败请求数量，及时发现问题
3. **响应时间**：监控平均处理时间，优化性能
4. **资源使用**：监控CPU、内存使用情况

## 🆘 故障排查

### 问题1：队列一直满

**可能原因**：
- 处理速度太慢
- 队列长度设置太小
- 有请求卡住

**解决方案**：
- 增加`MAX_QUEUE_SIZE`
- 检查是否有请求超时
- 重启服务清理卡住的请求

### 问题2：请求一直排队

**可能原因**：
- 当前请求处理时间过长
- 队列处理线程异常

**解决方案**：
- 检查日志，查看是否有异常
- 重启服务
- 检查评估器是否正常

### 问题3：请求超时

**可能原因**：
- 文本太长，处理时间超过超时时间
- 模型加载时间过长

**解决方案**：
- 增加`REQUEST_TIMEOUT`
- 使用`--preload`预加载模型
- 优化文本长度

## 📝 总结

请求队列机制可以有效解决多用户并发访问导致的服务器压力问题，通过单线程处理和排队机制，确保服务稳定运行。建议在生产环境中启用队列模式，并配合监控和告警机制，及时发现和解决问题。
